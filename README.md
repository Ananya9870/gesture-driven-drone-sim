Gesture-Driven Drone Simulator

A real-time hand gestureâ€“controlled drone simulator built using MediaPipe, OpenCV, and Python.
The system uses computer vision to detect hand gestures via a webcam and maps them to drone movements inside a 3D-style simulated environment with HUD and radar visualization.

âœ¨ Features

ğŸ–ï¸ Real-time hand gesture recognition using MediaPipe

ğŸš€ Gesture-based drone control

Rock â†’ Land

Open Palm â†’ Hover

Scissors â†’ Move Forward

Index Finger â†’ Move Backward

Three Fingers â†’ Move Left

ğŸ® 3D-style drone simulation

ğŸ“¡ Live radar widget with sweeping animation

ğŸ§  Gesture smoothing to reduce noise and false detection

ğŸ“Š On-screen HUD displaying gesture, drone state, and position

âš¡ Runs fully offline using a webcam

ğŸ› ï¸ Tech Stack

Python 3

OpenCV

MediaPipe

NumPy

ğŸ“‚ Project Structure
.
â”œâ”€â”€ main.py          # Main application file
â”œâ”€â”€ README.md        # Project documentation

â–¶ï¸ How It Works

Webcam captures live video feed.

MediaPipe detects hand landmarks.

Finger states are analyzed to classify gestures.

Gestures are stabilized using a frame history buffer.

Drone position is updated based on recognized gestures.

A simulated 3D environment renders:

Drone body & rotors

Perspective grid

Radar visualization

HUD text

ğŸ§‘â€âœˆï¸ Gesture Controls
Gesture	Action
âœŠ Rock (Fist)	Land
âœ‹ Open Palm	Hover
âœŒï¸ Index + Middle	Move Forward
â˜ï¸ Index Only	Move Backward
ğŸ¤Ÿ Index + Middle + Ring	Move Left
âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/gesture-driven-drone-simulator.git
cd gesture-driven-drone-simulator

2ï¸âƒ£ Install Dependencies
pip install opencv-python mediapipe numpy

3ï¸âƒ£ Run the Project
python main.py


ğŸ“· Ensure your webcam is connected and accessible

ğŸ–¥ï¸ Controls

Show gestures in front of the webcam

Press q to quit the application

ğŸ“¸ Demo Preview

(Optional: Add screenshots or a GIF here for better presentation)

ğŸš€ Use Cases

Computer Vision & AI demos

Gesture-based HCI systems

UAV/drone control research prototypes

Hackathons & academic projects

Assistive and touchless control interfaces

ğŸ“Œ Future Improvements

Add right & upward movement gestures

Integrate real drone (ROS / PX4 / DJI SDK)

Improve depth perception

Multi-hand gesture support

VR/AR visualization

ğŸ¤ Contributing

Contributions, ideas, and improvements are welcome!
Feel free to fork this repo and submit a pull request.
