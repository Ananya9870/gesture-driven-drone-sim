# ğŸš Gesture-Driven Drone Simulator âœ‹

Gesture-Driven Drone Simulator is a **computer visionâ€“based interactive simulation** where a virtual drone is controlled entirely using **hand gestures captured via a webcam** â€” no keyboard, mouse, or controller required.

The project leverages **MediaPipe Hand Tracking** and **OpenCV** to detect finger positions in real time and translate them into smooth drone movements inside a **3D-style simulated environment** with a **HUD and radar visualization**.

---

## ğŸš€ Features

* ğŸ¥ Real-time webcam-based interaction
* âœ‹ Hand gesture tracking using MediaPipe
* ğŸ§  Gesture stabilization to reduce noise and false positives
* ğŸš Gesture-based drone navigation (no physical controller)
* ğŸŒ 3D-style perspective grid simulation
* ğŸ“¡ Live radar widget with sweep animation
* ğŸ“Š Heads-Up Display (HUD) showing gesture & drone state
* âš¡ Fully offline & real-time performance
* ğŸ“ Beginner-friendly yet powerful computer vision logic

---

## ğŸ§‘â€âœˆï¸ Gesture Controls

| Gesture                  | Action        |
| ------------------------ | ------------- |
| âœŠ Rock (Fist)            | Land          |
| âœ‹ Open Palm              | Hover         |
| âœŒï¸ Index + Middle        | Move Forward  |
| â˜ï¸ Index Only            | Move Backward |
| ğŸ¤Ÿ Index + Middle + Ring | Move Left     |

---

## ğŸ› ï¸ Tech Stack

* Python 3
* OpenCV
* MediaPipe
* NumPy

---

## ğŸ“‚ Project Structure

```
gesture-driven-drone-simulator/
â”‚
â”œâ”€â”€ main.py                # Main application script
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ requirements.txt       # Python dependencies
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/gesture-driven-drone-simulator.git
cd gesture-driven-drone-simulator
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

If `requirements.txt` is not available:

```bash
pip install opencv-python mediapipe numpy
```

---

## â–¶ï¸ Run the Simulator

```bash
python main.py
```

ğŸ“· Ensure your **webcam is connected**
âŒ Press **q** to quit the application

---

## ğŸ§  How It Works

1. Captures live webcam frames using OpenCV
2. Detects hand landmarks with MediaPipe Hands
3. Analyzes finger positions to classify gestures
4. Smooths gestures using a frame-history buffer
5. Updates drone movement with world constraints
6. Renders a simulated environment featuring:

   * Perspective grid
   * Drone body & rotors
   * Radar visualization
   * Heads-Up Display (HUD)

---

## ğŸš€ Use Cases

* Computer Vision & AI demonstrations
* Gesture-based Humanâ€“Computer Interaction (HCI)
* UAV & drone navigation prototypes
* Hackathons and academic projects
* Touchless control systems

---

## ğŸ§ª Tested On

* Windows 10 / 11
* Python 3.9+
* Laptop webcam

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!
Feel free to **fork this repository** and submit a **pull request**.

---

## ğŸ“Œ Future Enhancements

* Altitude & rotation gestures
* Multi-drone simulation
* Physics-based drone dynamics
* VR/AR integration
* Real drone hardware mapping

---

â­ If you like this project, donâ€™t forget to **star the repository**!
